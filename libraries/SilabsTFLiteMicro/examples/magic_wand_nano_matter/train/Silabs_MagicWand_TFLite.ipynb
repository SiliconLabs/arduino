{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqMDAiZcrCg0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Setup environment\n",
        "\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounts Google Drive and copies a dataset folder (containing CSV files) locally\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Path to the folder\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/dataset'\n",
        "\n",
        "# List files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "print(files)\n",
        "\n",
        "!cp -r '/content/drive/My Drive/Colab Notebooks/dataset' './dataset'\n",
        "\n",
        "# List files in the copied folder\n",
        "local_files = os.listdir('./dataset')\n",
        "print(local_files)"
      ],
      "metadata": {
        "id": "CY4M7VlkJiSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots acceleration and gyroscope data from CSV files\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the folder containing the CSV files\n",
        "directory = 'dataset'\n",
        "\n",
        "# Get the list of CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
        "\n",
        "# Process each CSV file\n",
        "\n",
        "# Accelerometer data\n",
        "for filename in csv_files:\n",
        "    print(f\"Processing file (Acceleration): {filename}\")\n",
        "\n",
        "    # Load the data from the CSV file\n",
        "    df = pd.read_csv(os.path.join(directory, filename))\n",
        "\n",
        "    # Generate the index range\n",
        "    index = range(1, len(df['aX']) + 1)\n",
        "\n",
        "    # Plot Acceleration data\n",
        "    plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "    plt.plot(index, df['aX'], 'g.', label='x', linestyle='solid')\n",
        "    plt.plot(index, df['aY'], 'b.', label='y', linestyle='solid')\n",
        "    plt.plot(index, df['aZ'], 'r.', label='z', linestyle='solid')\n",
        "    plt.title(f\"Acceleration - {filename}\")\n",
        "    plt.xlabel(\"Sample #\")\n",
        "    plt.ylabel(\"Acceleration (mG)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Gyroscope data\n",
        "for filename in csv_files:\n",
        "    print(f\"Processing file (Gyroscope): {filename}\")\n",
        "\n",
        "    # Load the data from the CSV file\n",
        "    df = pd.read_csv(os.path.join(directory, filename))\n",
        "\n",
        "    # Generate the index range\n",
        "    index = range(1, len(df['gX']) + 1)\n",
        "\n",
        "    # Plot Acceleration data\n",
        "    plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "    plt.plot(index, df['gX'], 'g.', label='x', linestyle='solid')\n",
        "    plt.plot(index, df['gY'], 'b.', label='y', linestyle='solid')\n",
        "    plt.plot(index, df['gZ'], 'r.', label='z', linestyle='solid')\n",
        "    plt.title(f\"Gyroscope - {filename}\")\n",
        "    plt.xlabel(\"Sample #\")\n",
        "    plt.ylabel(\"Gyroscope (dps)\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lNi6Lh53L_3J",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads and processes gesture data from CSV files, normalizes the sensor values,\n",
        "# and prepares a dataset with input features and one-hot encoded labels for each gesture.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# the list of gestures that data is available for\n",
        "GESTURES = [\n",
        "    \"wing\", #W\n",
        "    \"ring\", #O\n",
        "    \"slope\", #L\n",
        "    \"nogesture\"\n",
        "]\n",
        "\n",
        "# the number of samples per gesture\n",
        "SAMPLES_PER_GESTURE = 100\n",
        "\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "  gesture = GESTURES[gesture_index]\n",
        "  print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n",
        "\n",
        "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
        "\n",
        "  df = pd.read_csv(\"dataset/\" + gesture + \".csv\")\n",
        "\n",
        "  # calculate the number of gesture recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
        "\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    for j in range(SAMPLES_PER_GESTURE):\n",
        "      index = i * SAMPLES_PER_GESTURE + j\n",
        "      tensor += [\n",
        "          (df['aX'][index]+2000)/4000,\n",
        "          (df['aY'][index]+2000)/4000,\n",
        "          (df['aZ'][index]+2000)/4000,\n",
        "          (df['gX'][index]+2000)/4000,\n",
        "          (df['gY'][index]+2000)/4000,\n",
        "          (df['gZ'][index]+2000)/4000\n",
        "      ]\n",
        "\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"\\nDataset parsing and preparation complete.\")\n",
        "print(f\"Shape of inputs: {inputs.shape}\")\n",
        "print(f\"Shape of outputs: {outputs.shape}\")"
      ],
      "metadata": {
        "id": "ZBFvlkAGr3SH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a fixed random seed value, for reproducibility, this will allow us to get the same random numbers each time the notebook is run\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the dataset into three sets: training 60%, testing 20% and validation 20%\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n",
        "print(f\"Shape of inputs train: {inputs_train.shape}\")\n",
        "print(f\"Shape of outputs train: {outputs_train.shape}\")\n",
        "print(f\"Shape of inputs test: {inputs_test.shape}\")\n",
        "print(f\"Shape of outputs test: {outputs_test.shape}\")\n",
        "print(f\"Shape of inputs validate: {inputs_validate.shape}\")\n",
        "print(f\"Shape of outputs validate: {outputs_validate.shape}\")"
      ],
      "metadata": {
        "id": "rhpmTPyLsKLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model and train it\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax'))  # Output layer with softmax activation, one unit per gesture (multi-class classification).\n",
        "\n",
        "# RMSProp adapts the learning rate, stabilizing training for gesture recognition.\n",
        "# Categorical cross-entropy is used for multi-class classification with one-hot encoded labels.\n",
        "# Accuracy tracks how many gestures are predicted correctly.\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model for 600 epochs with a batch size of 8.\n",
        "# Epochs: 600 means the model will train for 600 iterations over the entire dataset; increasing the number can improve accuracy, but it may also increase training time.\n",
        "# Batch size: 8 means the model processes 8 samples at a time before updating weights; smaller batch sizes can improve generalization but may increase training time.\n",
        "history = model.fit(inputs_train, outputs_train, epochs=600, batch_size=8, validation_data=(inputs_validate, outputs_validate))"
      ],
      "metadata": {
        "id": "ryigRrsS3t1i",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizes the training and validation loss and accuracy to help monitor the model's performance during training.\n",
        "# The plots help check if the model is improving and whether it is overfitting or underfitting.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get training and validation loss and accuracy\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Plot loss curves\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss, label='Training Loss', color='blue')\n",
        "plt.plot(val_loss, label='Validation Loss', color='red')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy, label='Training Accuracy', color='blue')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy', color='red')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EvI5udqcM6T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Verifica se c'Ã¨ una grande differenza tra predizioni e valori effettivi\n",
        "differences = np.abs(np.round(predictions, decimals=3) - outputs_test)\n",
        "print(\"Differences =\\n\", differences)\n",
        "\n",
        "threshold = 0.1  # Definisci una soglia di errore accettabile\n",
        "is_good_prediction = differences <= threshold\n",
        "print(\"Good predictions (within threshold) =\\n\", is_good_prediction)\n",
        "\n",
        "anomaly_threshold = 0.5  # Definisci una soglia per identificare anomalie\n",
        "anomalies = differences > anomaly_threshold\n",
        "print(\"Anomalies detected:\\n\", anomalies)\n",
        "\n",
        "correct_percentage = np.mean(differences < threshold) * 100\n",
        "print(f\"Percentage of good predictions (within threshold): {correct_percentage}%\")"
      ],
      "metadata": {
        "id": "dPQW-b1KtEYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Convert the model in TensorFlow Lite format\n",
        "\n",
        "def representative_dataset_gen():\n",
        "    for i in range(len(inputs_train)):  # Iterate over the entire training dataset\n",
        "        # Take a sample from the training data and convert it to float32 format\n",
        "        yield [inputs_train[i].astype(np.float32)]  # Ensure the data is in float32 format\n",
        "\n",
        "# Create the TFLite converter from the trained Keras model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Set optimizations for the model\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Set the representative dataset for calibration (needed for optimizations)\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "\n",
        "# Set the target specification for supported operations\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Set input and output types for inference to float32 (no quantization)\n",
        "converter.inference_input_type = tf.float32\n",
        "converter.inference_output_type = tf.float32\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the converted model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "# Get the model size and print it\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model size: %d bytes\" % basic_model_size)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FoPjOd7mIgRq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displays this information related to TFLite model to help understand the model's expected input/output format.\n",
        "\n",
        "# Load the TensorFlow Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"gesture_model.tflite\")\n",
        "\n",
        "# Get the number of inputs and outputs\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Show the number of inputs and outputs, and their shapes\n",
        "print(f\"Number of inputs: {len(input_details)}\")\n",
        "print(f\"Number of outputs: {len(output_details)}\")\n",
        "\n",
        "# Show the details of the inputs\n",
        "for i, input_detail in enumerate(input_details):\n",
        "    print(f\"Input {i}:\")\n",
        "    print(f\"  Type: {input_detail['dtype']}\")\n",
        "    print(f\"  Shape: {input_detail['shape']}\")\n",
        "    print(f\"  Number of dimensions: {len(input_detail['shape'])}\")\n",
        "\n",
        "# Show the details of the outputs\n",
        "for i, output_detail in enumerate(output_details):\n",
        "    print(f\"Output {i}:\")\n",
        "    print(f\"  Type: {output_detail['dtype']}\")\n",
        "    print(f\"  Shape: {output_detail['shape']}\")"
      ],
      "metadata": {
        "id": "BbU5oOUeuQ0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrates how to use a TFLite interpreter to process input data and obtain gesture recognition results.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"gesture_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get the input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Show the input and output details\n",
        "print(\"Input details:\", input_details)\n",
        "print(\"Output details:\", output_details)\n",
        "\n",
        "# Prepare the input data\n",
        "# Required shape: [1, 270], Type: float32\n",
        "input_shape = input_details[0]['shape']  # Get the input shape\n",
        "\n",
        "# Assume inputs_test is already defined as a NumPy array\n",
        "# Select a vector from inputs_test (e.g., the first vector)\n",
        "input_data = inputs_test[4]  # Select the first example (modify the index for another example)\n",
        "input_data = np.expand_dims(input_data, axis=0)  # Add batch dimension to make it [1, 270]\n",
        "input_data = input_data.astype(input_details[0]['dtype'])  # Ensure the type is float32\n",
        "\n",
        "# Set the input data to the model\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "# Perform inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the results\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# Print the results\n",
        "print(\"Input data:\", input_data)\n",
        "print(\"Inference result:\", output_data)"
      ],
      "metadata": {
        "id": "wXr5zpOErSRF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert TFLite file in .c file\n",
        "\n",
        "!echo \"// Auto-generated serialization of TFLite flatbuffers\" > /content/sl_tflite_micro_model.c\n",
        "!echo \"\" >> /content/sl_tflite_micro_model.c\n",
        "!echo \"#include \\\"em_device.h\\\"\" >> /content/sl_tflite_micro_model.c\n",
        "!echo \"#include \\\"sl_tflite_micro_model.h\\\"\" >> /content/sl_tflite_micro_model.c\n",
        "!echo \"\" >> /content/sl_tflite_micro_model.c\n",
        "!echo \"// Model data generated from .tflite file\" >> /content/sl_tflite_micro_model.c\n",
        "!echo \"const uint8_t sl_tflite_model_array[] __ALIGNED(4) = {\" >> /content/sl_tflite_micro_model.c\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/sl_tflite_micro_model.c\n",
        "!echo \"};\"                              >> /content/sl_tflite_micro_model.c\n",
        "model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "!echo \"const uint32_t sl_tflite_model_len = {model_size}UL;\" >> /content/sl_tflite_micro_model.c\n",
        "\n",
        "print(\"Model size: %d bytes\" % model_size)\n",
        "model_h_size = os.path.getsize(\"sl_tflite_micro_model.c\")\n",
        "print(f\"sl_tflite_micro_model.c size: {model_h_size:,} bytes.\")"
      ],
      "metadata": {
        "id": "y2aIo7pXIa8l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}